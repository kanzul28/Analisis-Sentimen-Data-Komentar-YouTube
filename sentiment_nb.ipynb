{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_positive = 1 \n",
    "label_negative = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Kanzul Faisal\\Documents\\Proposal PI\\Project PI\\PreProcessing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[[0, 4]], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test data\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(df['Komentar_Final'], df['Label'], test_size = 0.2,random_state = 20)\n",
    "# random_state = 20 menyatakan kita akan mendapatkan output yang sama dengan saat pertama kali membuat pemisahan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_train['Sentiment'] = train_X\n",
    "df_train['Label'] = train_Y\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['Sentiment'] = test_X\n",
    "df_test['Label'] = test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(label):\n",
    "  if label == 'positif':\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "df_train['Label'] = train_Y.apply(convert)\n",
    "df_test['Label'] = test_Y.apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(max_features = 5000)\n",
    "# tfidf_vect.fit(df_train['Sentiment'])\n",
    "tfidf_vect.fit(df['Komentar_Final'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"selected words as feature : \")\n",
    "print(\"----------------------------\")\n",
    "print(tfidf_vect.get_feature_names())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You can use the below syntax to see the vocabulary that it has learned from the corpus\n",
    "print(tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"jumlah data training : \")\n",
    "print(len(train_X))\n",
    "print()\n",
    "\n",
    "print(\"jumlah data test : \") \n",
    "print(len(test_X))\n",
    "print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tfidf = tfidf_vect.transform(df_train['Sentiment'])\n",
    "test_X_tfidf = tfidf_vect.transform(df_test['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_mat = tfidf_vect.transform(df['Komentar_Final']).toarray()\n",
    "tfidf_mat = tfidf_vect.transform(df_train['Sentiment']).toarray()\n",
    "# tfidf_mat = tfidf_vect.transform(df_test['Sentiment']).toarray()\n",
    "\n",
    "terms = tfidf_vect.get_feature_names()\n",
    "\n",
    "# menjumlahkan tfidf dari tiap kata/term di semua dataset\n",
    "sums = tfidf_mat.sum(axis=0)\n",
    "\n",
    "# menampilkan jumlah tfidf dari tiap kata yang ada di dataset\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append((term, sums[col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','TF-IDF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_br=ranking.sort_values('TF-IDF', ascending=False)\n",
    "print(ranking_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_br.to_csv(r'C:\\Users\\Kanzul Faisal\\Documents\\Proposal PI\\Project PI\\tfidf_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(train_X_tfidf,df_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_X_tfidf)\n",
    "acc = (accuracy_score(df_test['Label'],predict))*100\n",
    "\n",
    "print(round(acc,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(df_test['Label'], predict)\n",
    "print(\"Confusion Matrix : \") \n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "f, ax = plt.subplots(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix(df_test['Label'], predict), annot=True, fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"predict\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.savefig(r\"C:\\Users\\Kanzul Faisal\\Documents\\Proposal PI\\Project PI\\visualisasi data\\confusion matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Accuracy, Precision, Recall, f1-score\n",
    "print (\"\\nHere is the classification report:\") \n",
    "print (classification_report(df_test['Label'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung jumlah label positif dan negatif pada data test setelah hasil prediksi model\n",
    "test_after_nb_count_label = collections.Counter(predict)\n",
    "juml_pos_nb= test_after_nb_count_label[label_positive]\n",
    "juml_neg_nb = test_after_nb_count_label[label_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie chart analisis sentimen\n",
    "labels = ['Positive','Negative']\n",
    "Category = [juml_pos_nb, juml_neg_nb]\n",
    "fig, ax = plt.subplots()\n",
    "color = ['blue', 'red']\n",
    "plt.pie(Category, labels=labels, colors=color,startangle=90, shadow=True, autopct='%1.2f%%', explode=(0.1, 0))\n",
    "plt.title('Diagram Lingkar Data Hasil Prediksi Klasifikasi Naive Bayes')\n",
    "plt.legend()\n",
    "plt.savefig(r\"C:\\Users\\Kanzul Faisal\\Documents\\Proposal PI\\Project PI\\visualisasi data\\pie_nb.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamus_kata = pd.read_csv(r'C:\\Users\\Kanzul Faisal\\Documents\\Proposal PI\\Project PI\\tfidf_train.csv')\n",
    "kamus_kata.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kamus_kata['Unnamed: 0']\n",
    "kamus_kata.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,\n",
    "            open('model_nb.pkl', 'wb'),\n",
    "            protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_vect,\n",
    "            open('tfidf.pkl', 'wb'),\n",
    "            protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
